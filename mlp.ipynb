{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torchvision\r\n",
    "from torchvision import transforms, datasets\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# ---- data loading and pre-processing ---- #\r\n",
    "\r\n",
    "import polar_pla as pla\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torch.autograd import Variable\r\n",
    "\r\n",
    "# read in time series into temporary list\r\n",
    "temp = []\r\n",
    "f = open('DataSets/AirPassengers.csv', 'r')\r\n",
    "for line in f:\r\n",
    "    temp.append(float(line))\r\n",
    "\r\n",
    "# run bottom up piecewise linear approximation on that list and store processed values\r\n",
    "data = pla.bottom_up_pla(temp, 200)\r\n",
    "#print(data)\r\n",
    "# set the sequence length (the number of trends we look at to predict the next) and the train to test ratio\r\n",
    "seq_length = 12\r\n",
    "train_proportion = 0.8\r\n",
    "\r\n",
    "# segment the data into input output pairs that we will use to train the model\r\n",
    "def sliding_window(data):\r\n",
    "    inputs = []\r\n",
    "    outputs = []\r\n",
    "    for i in range(0, len(data)-seq_length, 2):\r\n",
    "        inputs.append(data[i:(i+seq_length)]) # the next n are the input\r\n",
    "        outputs.append(data[i+seq_length:i+seq_length+2]) # and the one after that is the output\r\n",
    "    return Variable(torch.Tensor(np.array(inputs))), Variable(torch.Tensor(np.array(outputs)))\r\n",
    "\r\n",
    "# convert data to tensor, and apply dataloader\r\n",
    "total_data_input, total_data_output = sliding_window(data)\r\n",
    "train_size = int(len(total_data_input)*train_proportion)\r\n",
    "\r\n",
    "training_data_input = torch.narrow(total_data_input, 0, 0, train_size)\r\n",
    "training_data_output = torch.narrow(total_data_output, 0, 0, train_size)\r\n",
    "\r\n",
    "testing_data_input = torch.narrow(total_data_input, 0, train_size, len(total_data_input) - train_size)\r\n",
    "testing_data_output = torch.narrow(total_data_output, 0, train_size, len(total_data_input) - train_size)\r\n",
    "\r\n",
    "train = torch.utils.data.TensorDataset(training_data_input, training_data_output)\r\n",
    "test = torch.utils.data.TensorDataset(testing_data_input, testing_data_output)\r\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=32, shuffle=False)\r\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\PiecewiseLinearSegmentation\\bottomup.py:27: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  ( p, residuals, rank, s ) = lstsq( X, y )\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Net(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.fc1 = nn.Linear(seq_length, 64)\r\n",
    "        self.fc2 = nn.Linear(64, 64)\r\n",
    "        self.fc3 = nn.Linear(64, 64)\r\n",
    "        self.fc4 = nn.Linear(64, 2)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.fc1(x)\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = F.relu(self.fc3(x))\r\n",
    "        x = self.fc4(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "net = Net()\r\n",
    "print(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=12, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# training\r\n",
    "\r\n",
    "epochs = 100\r\n",
    "\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\r\n",
    "for epoch in range(epochs+1): # 3 full passes over the data\r\n",
    "    for data in trainset:  # `data` is a batch of data\r\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\r\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\r\n",
    "        output = net(X.view(-1,seq_length))  # pass in the reshaped batch (recall they are 28x28 atm)\r\n",
    "        #print(X)\r\n",
    "        #print(output, y)\r\n",
    "        loss = F.mse_loss(output, y)  # calc and grab the loss value\r\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\r\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\r\n",
    "    if epoch %(epochs/10) == 0: print(f\"Epoch: {epoch}/{epochs}, loss: {loss.item()}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0/100, loss: 256.8272705078125\n",
      "Epoch: 10/100, loss: 86.89999389648438\n",
      "Epoch: 20/100, loss: 15.701323509216309\n",
      "Epoch: 30/100, loss: 1.1277779340744019\n",
      "Epoch: 40/100, loss: 0.291513592004776\n",
      "Epoch: 50/100, loss: 0.15554466843605042\n",
      "Epoch: 60/100, loss: 0.08605650067329407\n",
      "Epoch: 70/100, loss: 0.08162877708673477\n",
      "Epoch: 80/100, loss: 0.16843490302562714\n",
      "Epoch: 90/100, loss: 0.19245152175426483\n",
      "Epoch: 100/100, loss: 0.20379403233528137\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# test\r\n",
    "'''import matplotlib.pyplot as plt\r\n",
    "with torch.no_grad():\r\n",
    "    av_loss = 0 \r\n",
    "    i = 0\r\n",
    "    X, Y = [], []\r\n",
    "    X2, Y2 = [], []\r\n",
    "    for data in test:\r\n",
    "        inputs, labels = data\r\n",
    "        output = net(inputs.view(-1,8))[0]\r\n",
    "\r\n",
    "        X.append(float(output[0]))\r\n",
    "        Y.append(float(output[1]))\r\n",
    "        X2.append(float(labels[0]))\r\n",
    "        Y2.append(float(labels[1]))\r\n",
    "\r\n",
    "    plt.plot(X, Y)\r\n",
    "    plt.plot(X2,Y2)\r\n",
    "    plt.show()'''\r\n",
    "with torch.no_grad():\r\n",
    "    correct = 0\r\n",
    "    i = 0\r\n",
    "    X, Y = [], []\r\n",
    "    X2, Y2 = [], []\r\n",
    "    total_loss = 0\r\n",
    "    for data in test:\r\n",
    "        inputs, labels = data\r\n",
    "        output = net(inputs.view(-1,seq_length))\r\n",
    "        loss += F.mse_loss(output, y)\r\n",
    "        output = output[0]\r\n",
    "        if output[0] < 0 and labels[0] < 0 or output[0] > 0 and labels[0] > 0:\r\n",
    "            correct += 1\r\n",
    "            #print(output[0],labels[0])\r\n",
    "    print(correct/len(test),loss.item()/len(test))\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7777777777777778 6984.502604166667\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-9-f021038da10f>:29: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss += F.mse_loss(output, y)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3cd23b357b5bb7eb022598bbb7741c98d84dc142569d56aec53a2cc58ec68b49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}